/* tslint:disable */
/* eslint-disable */

/* auto-generated by NAPI-RS */

/**
 * Ownership commitment binding data to a public key.
 * 
 * This structure represents the cryptographic proof that a specific public key
 * owns a particular piece of data. It's used as the foundation for the entire
 * HashChain Proof of Storage Continuity system.
 * 
 * **Cryptographic Construction:**
 * `commitment_hash = SHA256(data_hash || public_key)`
 * 
 * This creates an unforgeable link between the data and the owner's public key,
 * preventing unauthorized parties from claiming ownership of stored data.
 * 
 * @example
 * ```typescript
 * // Create ownership commitment
 * const publicKey = Buffer.from('your_32_byte_public_key...', 'hex');
 * const dataHash = Buffer.from('sha256_of_your_data...', 'hex');
 * 
 * const ownership = createOwnershipCommitment(publicKey, dataHash);
 * console.log('Owner:', ownership.publicKey.toString('hex'));
 * console.log('Data:', ownership.dataHash.toString('hex'));
 * console.log('Commitment:', ownership.commitmentHash.toString('hex'));
 * 
 * // Verify ownership
 * const expectedHash = sha256(Buffer.concat([dataHash, publicKey]));
 * console.log('Valid:', ownership.commitmentHash.equals(expectedHash));
 * ```
 */
export interface OwnershipCommitment {
  /** Prover's public key (32 bytes) - identifies who owns the data */
  publicKey: Buffer
  /** SHA256 hash of the data (32 bytes) - unique identifier for the data content */
  dataHash: Buffer
  /** SHA256(data_hash || public_key) (32 bytes) - cryptographic binding of ownership */
  commitmentHash: Buffer
}

/**
 * Block commitment from blockchain.
 * 
 * Links the HashChain to a specific block on the Chia blockchain, providing
 * tamper-evident timestamping and entropy for unpredictable chunk selection.
 * This prevents backdating attacks and ensures fair chunk selection.
 * 
 * **Network Requirements:**
 * - Block hash must be exactly 32 bytes
 * - Block height must be valid and increasing
 * - Block must exist on the canonical Chia blockchain
 * 
 * @example
 * ```typescript
 * // Create block commitment from Chia blockchain data
 * const blockCommitment: BlockCommitment = {
 *   blockHeight: 12345,
 *   blockHash: Buffer.from('abc123def456...', 'hex') // 32 bytes
 * };
 * 
 * // Use in anchored commitment
 * const anchored = createAnchoredOwnershipCommitment(ownership, blockCommitment);
 * console.log('Anchored at block:', blockCommitment.blockHeight);
 * ```
 */
export interface BlockCommitment {
  /** Block height from Chia blockchain - sequential numbering for temporal ordering */
  blockHeight: number
  /** Block hash from Chia blockchain (32 bytes) - cryptographic block identifier and entropy source */
  blockHash: Buffer
}

/**
 * Anchored ownership commitment combining ownership and blockchain state.
 * 
 * This creates an immutable link between data ownership and a specific point
 * in blockchain history, preventing backdating attacks and establishing
 * provable commitment timing. Once anchored, the ownership cannot be changed
 * or moved to an earlier time.
 * 
 * **Security Properties:**
 * - Prevents ownership backdating attacks
 * - Provides cryptographic timestamping
 * - Creates audit trail for ownership establishment
 * - Links to immutable blockchain state
 * 
 * **Cryptographic Construction:**
 * `anchored_hash = SHA256(ownership_commitment_hash || block_hash)`
 * 
 * @example
 * ```typescript
 * // Create complete anchored ownership
 * const ownership = createOwnershipCommitment(publicKey, dataHash);
 * const blockCommitment = { blockHeight: 12345, blockHash: Buffer.from('...') };
 * 
 * const anchored = createAnchoredOwnershipCommitment(ownership, blockCommitment);
 * 
 * console.log('Ownership anchored:', {
 *   owner: anchored.ownershipCommitment.publicKey.toString('hex').slice(0, 8) + '...',
 *   data: anchored.ownershipCommitment.dataHash.toString('hex').slice(0, 8) + '...',
 *   block: anchored.blockCommitment.blockHeight,
 *   anchored: anchored.anchoredHash.toString('hex').slice(0, 8) + '...'
 * });
 * 
 * // This anchored commitment becomes the root of the HashChain
 * ```
 */
export interface AnchoredOwnershipCommitment {
  /** The ownership commitment linking data to public key */
  ownershipCommitment: OwnershipCommitment
  /** The blockchain commitment providing immutable timestamping */
  blockCommitment: BlockCommitment
  /** SHA256(ownership_commitment || block_hash) (32 bytes) - final anchored hash */
  anchoredHash: Buffer
}

/**
 * Physical access commitment proving data access at specific block.
 * 
 * Each commitment proves that the prover had physical access to the actual data
 * at the time of a specific blockchain block. This is accomplished by demonstrating
 * the ability to read unpredictably selected chunks from the data file.
 * 
 * **Proof Mechanism:**
 * 1. Block hash provides unpredictable entropy
 * 2. Deterministic algorithm selects 4 unique chunks
 * 3. Prover reads and hashes the selected chunks
 * 4. Commitment cryptographically links all data together
 * 
 * **Network Consensus Requirements:**
 * - Chunk selection must follow consensus algorithm V1
 * - Exactly 4 chunks must be selected per block
 * - Chunks must be unique within the commitment
 * - Commitment hash must include all relevant data
 * - Sequential linking to previous commitment required
 * 
 * @example
 * ```typescript
 * // Generated during block addition
 * const blockHash = Buffer.from('new_block_hash_32_bytes...', 'hex');
 * const commitment = hashchain.addBlock(blockHash);
 * 
 * console.log('New commitment:', {
 *   block: commitment.blockHeight,
 *   selectedChunks: commitment.selectedChunks, // [123, 456, 789, 1011]
 *   chunkHashes: commitment.chunkHashes.map(h => h.toString('hex').slice(0, 8) + '...'),
 *   commitment: commitment.commitmentHash.toString('hex').slice(0, 8) + '...'
 * });
 * 
 * // Verify chunk selection follows consensus
 * const isValid = verifyChunkSelection(
 *   commitment.blockHash,
 *   totalChunks,
 *   commitment.selectedChunks,
 *   1 // algorithm version
 * );
 * console.log('Consensus compliant:', isValid);
 * ```
 */
export interface PhysicalAccessCommitment {
  /** Blockchain block height when this commitment was created */
  blockHeight: number
  /** Previous commitment in chain (32 bytes) - ensures sequential integrity */
  previousCommitment: Buffer
  /** Current block hash (32 bytes) - provides entropy for chunk selection */
  blockHash: Buffer
  /** Indices of selected chunks - deterministically chosen based on block hash */
  selectedChunks: Array<number>
  /** SHA256 hashes of selected chunks - cryptographic proof of data access */
  chunkHashes: Array<Buffer>
  /** SHA256 of all above fields (32 bytes) - commitment integrity hash */
  commitmentHash: Buffer
}

/**
 * HashChain file header with metadata.
 * 
 * Contains all necessary information to validate and reconstruct the HashChain,
 * including file format version, data integrity hashes, consensus parameters,
 * and structural metadata. This header ensures network consensus compliance
 * and enables proper validation by all participants.
 * 
 * **File Format Compliance:**
 * All fields must match the network consensus specification exactly.
 * Any deviation will result in rejection by network validators.
 * 
 * **Binary Layout (184 bytes total):**
 * - Offset 0-3: Magic number 'HCHN' (4 bytes)
 * - Offset 4-7: Format version (4 bytes, uint32)
 * - Offset 8-39: Original data file SHA256 hash (32 bytes)
 * - Offset 40-71: Merkle root of chunks (32 bytes)
 * - Offset 72-79: Total chunks count (8 bytes, uint64)
 * - Offset 80-83: Chunk size in bytes (4 bytes, uint32)
 * - Offset 84-115: Data file path hash SHA256 (32 bytes)
 * - Offset 116-147: Anchored ownership commitment (32 bytes)
 * - Offset 148-151: Hash chain length (4 bytes, uint32)
 * - Offset 152-183: Header checksum SHA256 (32 bytes)
 * 
 * @example
 * ```typescript
 * // Access header information from loaded HashChain
 * const hashchain = HashChain.loadFromFile('data.hashchain');
 * const info = hashchain.getChainInfo();
 * 
 * console.log('File format compliance:', {
 *   magic: 'HCHN', // Always this value
 *   version: 1, // Current format version
 *   totalChunks: info.totalChunks,
 *   chunkSize: info.chunkSizeBytes, // Always 4096
 *   chainLength: info.chainLength
 * });
 * ```
 */
export interface HashChainHeader {
  /** File format identifier b'HCHN' - magic number for file type detection */
  magic: Buffer
  /** Format version (must match HASHCHAIN_FORMAT_VERSION) - for backwards compatibility */
  formatVersion: number
  /** SHA256 of original data file (32 bytes) - data integrity verification */
  dataFileHash: Buffer
  /** Merkle root of chunks (32 bytes) - efficient chunk verification */
  merkleRoot: Buffer
  /** Number of chunks (use f64 for large numbers in JS) - total data chunks */
  totalChunks: number
  /** Size of each chunk in bytes (4096) - standardized chunk size */
  chunkSize: number
  /** SHA256 of data file path for binding (32 bytes) - path integrity */
  dataFilePathHash: Buffer
  /** Initial anchored commitment (32 bytes) - chain starting point */
  anchoredCommitment: Buffer
  /** Number of chain links (4 bytes) - current chain length */
  chainLength: number
  /** SHA256 of header fields 0-151 (32 bytes) - header integrity check */
  headerChecksum: Buffer
}

/**
 * Proof window containing last 8 commitments for verification.
 * 
 * The proof window represents the minimum required proof for network submission.
 * It contains 8 consecutive block commitments plus all necessary Merkle proofs
 * to verify chunk authenticity without access to the original data.
 * 
 * **Network Requirements:**
 * - Exactly 8 commitments (PROOF_WINDOW_BLOCKS)
 * - Sequential block heights with no gaps
 * - All Merkle proofs present for selected chunks (32 total)
 * - Cryptographically linked chain of commitments
 * - Verifiable against anchored commitment
 * 
 * **Proof Structure:**
 * - 8 blocks × 4 chunks = 32 chunk selections total
 * - 32 Merkle proofs for chunk authenticity
 * - Start commitment links to proof window beginning
 * - End commitment represents current chain state
 * 
 * **Validation Process:**
 * 1. Verify exactly 8 sequential commitments
 * 2. Check commitment chain integrity
 * 3. Validate chunk selections follow consensus
 * 4. Verify all Merkle proofs against root
 * 5. Confirm proper linking to anchored commitment
 * 
 * @example
 * ```typescript
 * // Generate proof window after 8+ blocks
 * if (hashchain.getChainLength() >= 8) {
 *   const proofWindow = hashchain.getProofWindow();
 *   
 *   console.log('Proof window:', {
 *     commitments: proofWindow.commitments.length, // 8
 *     merkleProofs: proofWindow.merkleProofs.length, // 32 (8 blocks × 4 chunks)
 *     timespan: {
 *       start: proofWindow.startCommitment.toString('hex').slice(0, 8) + '...',
 *       end: proofWindow.endCommitment.toString('hex').slice(0, 8) + '...'
 *     }
 *   });
 *   
 *   // Verify the proof before network submission
 *   const isValid = verifyProof(
 *     proofWindow,
 *     hashchain.getAnchoredCommitment(),
 *     merkleRoot,
 *     hashchain.getTotalChunks()
 *   );
 *   
 *   if (isValid) {
 *     console.log('✅ Proof valid - ready for network submission');
 *     // Submit to network validators
 *   } else {
 *     console.log('❌ Proof invalid - do not submit');
 *   }
 * } else {
 *   console.log(`⏳ Need ${8 - hashchain.getChainLength()} more blocks`);
 * }
 * ```
 */
export interface ProofWindow {
  /** Last 8 commitments - sequential proof of continuous storage */
  commitments: Array<PhysicalAccessCommitment>
  /** Merkle proofs for selected chunks - cryptographic chunk verification */
  merkleProofs: Array<Buffer>
  /** Commitment from 8 blocks ago - proof window starting point */
  startCommitment: Buffer
  /** Latest commitment - proof window ending point */
  endCommitment: Buffer
}

/**
 * Result of chunk selection with verification data.
 * 
 * Contains the deterministic chunk selection results plus verification metadata
 * to ensure consensus compliance across all network participants. This structure
 * enables validation that chunk selection followed the exact consensus algorithm.
 * 
 * **Consensus Critical:**
 * All network participants MUST produce identical results for the same inputs.
 * Any deviation indicates a consensus failure and will be rejected by validators.
 * 
 * **Algorithm Properties:**
 * - Deterministic: Same inputs always produce same outputs
 * - Unpredictable: Cannot be computed without block hash
 * - Uniform: All chunks have equal selection probability
 * - Unique: No duplicate chunks within single selection
 * 
 * **Verification Process:**
 * The verification hash enables quick validation without re-running the algorithm:
 * `verification_hash = SHA256(version || block_hash || total_chunks || sorted_indices)`
 * 
 * @example
 * ```typescript
 * // Generate chunk selection
 * const blockHash = Buffer.from('block_hash_32_bytes...', 'hex');
 * const totalChunks = 1000;
 * 
 * const result = selectChunksV1(blockHash, totalChunks);
 * console.log('Selection result:', {
 *   algorithm: `v${result.algorithmVersion}`, // v1
 *   chunks: result.selectedIndices, // [123, 456, 789, 1011]
 *   entropy: result.blockHash.toString('hex').slice(0, 8) + '...',
 *   verification: result.verificationHash.toString('hex').slice(0, 8) + '...'
 * });
 * 
 * // Verify consensus compliance
 * const isValid = verifyChunkSelection(
 *   blockHash,
 *   totalChunks,
 *   result.selectedIndices,
 *   result.algorithmVersion
 * );
 * console.log('Consensus compliant:', isValid); // Must be true
 * 
 * // Use selected chunks for commitment
 * for (const chunkIdx of result.selectedIndices) {
 *   const chunk = hashchain.readChunk(chunkIdx);
 *   const chunkHash = sha256(chunk);
 *   console.log(`Chunk ${chunkIdx}:`, chunkHash.toString('hex').slice(0, 8) + '...');
 * }
 * ```
 */
export interface ChunkSelectionResult {
  /** Selected chunk indices - deterministically chosen chunks to verify */
  selectedIndices: Array<number>
  /** Algorithm version used - for consensus compatibility tracking */
  algorithmVersion: number
  /** Total chunks in file - verification parameter */
  totalChunks: number
  /** Block hash used for selection - entropy source */
  blockHash: Buffer
  /** Hash of selection parameters for verification - consensus validation */
  verificationHash: Buffer
}

/**
 * Human-readable information about HashChain state.
 * 
 * Provides comprehensive status information for monitoring, debugging,
 * and user interface display. Includes file system details, storage metrics,
 * commitment tracking, and proof readiness status.
 * 
 * **Status Values:**
 * - `"uninitialized"` - No data has been streamed yet
 * - `"initialized"` - Data streamed, but no blocks added
 * - `"building"` - Blocks added, but < 8 blocks (proof window not ready)
 * - `"active"` - 8+ blocks added, proof window ready for network submission
 * 
 * **Use Cases:**
 * - **Status Monitoring**: Check if chain is ready for proof generation
 * - **Storage Management**: Monitor file sizes and storage requirements  
 * - **Debugging**: Inspect commitment hashes and chain state
 * - **UI Display**: Show user-friendly chain status in applications
 * - **Performance Tracking**: Monitor chain growth and file sizes
 * - **Network Compliance**: Verify algorithm version and consensus parameters
 * 
 * **File Size Information:**
 * - `hashchainFileSizeBytes`: Size of .hashchain metadata file
 * - `dataFileSizeBytes`: Size of .data file containing actual chunk data
 * - `totalStorageMb`: Calculated storage requirement (chunks × 4096 bytes)
 * 
 * **Commitment Tracking:**
 * - `anchoredCommitment`: Initial commitment hash (hex string)
 * - `currentCommitment`: Latest commitment hash (hex string)
 * - Use for verifying chain continuity and tracking progress
 * 
 * @example
 * ```typescript
 * // Basic usage - check chain status
 * const hashchain = new HashChain(publicKey, blockHeight, blockHash);
 * hashchain.streamData(data, outputDir);
 * 
 * const info = hashchain.getChainInfo();
 * console.log('HashChain Status:', info.status); // "initialized"
 * console.log('Total Chunks:', info.totalChunks); // e.g., 1024
 * console.log('Storage Required:', info.totalStorageMb.toFixed(2), 'MB'); // e.g., "4.00 MB"
 * 
 * // Monitor proof readiness
 * if (info.proofWindowReady) {
 *   console.log('✅ Ready for proof generation!');
 *   const proofWindow = hashchain.getProofWindow();
 * } else {
 *   console.log(`⏳ Need ${info.blocksUntilProofReady} more blocks for proof window`);
 * }
 * 
 * // File system information
 * console.log('Files:', {
 *   hashchain: info.hashchainFilePath,
 *   data: info.dataFilePath,
 *   sizes: {
 *     hashchainMB: (info.hashchainFileSizeBytes / 1024 / 1024).toFixed(2),
 *     dataMB: (info.dataFileSizeBytes / 1024 / 1024).toFixed(2)
 *   }
 * });
 * 
 * // Commitment tracking
 * console.log('Commitments:', {
 *   anchored: info.anchoredCommitment?.slice(0, 8) + '...',
 *   current: info.currentCommitment?.slice(0, 8) + '...',
 *   blocksAdded: info.chainLength
 * });
 * 
 * // Display formatted summary
 * function displayHashChainSummary(info: HashChainInfo) {
 *   console.log(`
 * 🔗 HashChain Summary
 * ==================
 * Status: ${info.status.toUpperCase()}
 * Chunks: ${info.totalChunks} × ${info.chunkSizeBytes} bytes
 * Storage: ${info.totalStorageMb.toFixed(2)} MB
 * Chain Length: ${info.chainLength} blocks
 * Proof Ready: ${info.proofWindowReady ? '✅ YES' : '❌ NO'}
 * Algorithm: v${info.consensusAlgorithmVersion}
 *   `);
 * }
 * 
 * displayHashChainSummary(info);
 * ```
 */
export interface HashChainInfo {
  /** Current status: "uninitialized", "initialized", "building", "active" */
  status: string
  /** Total number of chunks in the data file */
  totalChunks: number
  /** Number of blocks added to the chain */
  chainLength: number
  /** Size of each chunk in bytes (4096) */
  chunkSizeBytes: number
  /** Total storage required in MB */
  totalStorageMb: number
  /** Path to .hashchain file - undefined if not initialized */
  hashchainFilePath?: string
  /** Path to .data file - undefined if not initialized */
  dataFilePath?: string
  /** Size of .hashchain file in bytes - undefined if not initialized */
  hashchainFileSizeBytes?: number
  /** Size of .data file in bytes - undefined if not initialized */
  dataFileSizeBytes?: number
  /** Anchored commitment hash (hex) - undefined if not initialized */
  anchoredCommitment?: string
  /** Current commitment hash (hex) - undefined if not initialized */
  currentCommitment?: string
  /** Whether proof window is ready (8+ blocks) */
  proofWindowReady: boolean
  /** Blocks remaining until proof window ready - undefined if ready */
  blocksUntilProofReady?: number
  /** Consensus algorithm version */
  consensusAlgorithmVersion: number
  /** Initial blockchain block height */
  initialBlockHeight: number
}

/**
 * CONSENSUS CRITICAL: Standardized chunk selection algorithm V1.
 * 
 * Deterministically selects 4 unique chunks from the data file based on the
 * provided block hash. This algorithm MUST produce identical results across
 * all network participants to maintain consensus.
 * 
 * **Algorithm Details:**
 * - Uses SHA256-based seed generation from block hash
 * - Selects exactly 4 unique chunks per block
 * - Maximum 16 attempts to find unique chunks
 * - Modulo-based index calculation for uniform distribution
 * 
 * **Consensus Requirements:**
 * - Block hash must be exactly 32 bytes
 * - Total chunks must be ≥ 4 (CHUNKS_PER_BLOCK)
 * - Results must be reproducible across all implementations
 * 
 * @param blockHash - Blockchain block hash (32 bytes) providing entropy
 * @param totalChunks - Total number of chunks in the data file
 * @returns ChunkSelectionResult with selected indices and verification data
 * 
 * @throws {Error} If block hash is not 32 bytes
 * @throws {Error} If total chunks is less than CHUNKS_PER_BLOCK (4)
 * @throws {Error} If unable to find 4 unique chunks within 16 attempts
 * 
 * @example
 * ```typescript
 * const blockHash = Buffer.from('0123456789abcdef...', 'hex'); // 32 bytes
 * const totalChunks = 1000;
 * 
 * const result = selectChunksV1(blockHash, totalChunks);
 * console.log('Selected chunks:', result.selectedIndices); // [123, 456, 789, 1011]
 * console.log('Algorithm version:', result.algorithmVersion); // 1
 * 
 * // Verify consensus compliance
 * const isValid = verifyChunkSelection(
 *   blockHash,
 *   totalChunks,
 *   result.selectedIndices,
 *   1
 * );
 * console.log('Consensus valid:', isValid); // true
 * ```
 */
export declare function selectChunksV1(blockHash: Buffer, totalChunks: number): ChunkSelectionResult

/**
 * Verify chunk selection matches network consensus algorithm.
 * 
 * Validates that a claimed chunk selection was generated using the correct
 * consensus algorithm and produces the expected results. This function is
 * used by network validators to ensure all participants follow the same rules.
 * 
 * **Validation Steps:**
 * 1. Re-runs the standardized algorithm with provided inputs
 * 2. Compares results with claimed indices
 * 3. Verifies exact order preservation (consensus requirement)
 * 4. Checks algorithm version compatibility
 * 
 * @param blockHash - Block hash used for chunk selection (32 bytes)
 * @param totalChunks - Total chunks in the data file
 * @param claimedIndices - Chunk indices claimed to be selected
 * @param expectedAlgorithmVersion - Expected algorithm version (default: current)
 * @returns true if chunk selection is consensus-compliant, false otherwise
 * 
 * @example
 * ```typescript
 * // Verify a chunk selection from another participant
 * const isValid = verifyChunkSelection(
 *   blockHash,
 *   totalChunks,
 *   [123, 456, 789, 1011], // Claimed selection
 *   1 // Algorithm version
 * );
 * 
 * if (isValid) {
 *   console.log('✅ Selection follows consensus rules');
 * } else {
 *   console.log('❌ Invalid selection - consensus violation');
 * }
 * ```
 */
export declare function verifyChunkSelection(blockHash: Buffer, totalChunks: number, claimedIndices: Array<number>, expectedAlgorithmVersion?: number | undefined | null): boolean

/**
 * Create ownership commitment.
 * 
 * Generates a cryptographic commitment proving that a specific public key
 * owns a particular piece of data. This forms the foundation of the
 * HashChain ownership model.
 * 
 * **Cryptographic Construction:**
 * `commitment_hash = SHA256(data_hash || public_key)`
 * 
 * @param publicKey - Owner's public key (32 bytes)
 * @param dataHash - SHA256 hash of the data (32 bytes)
 * @returns OwnershipCommitment with cryptographic binding
 * 
 * @throws {Error} If public key or data hash is not exactly 32 bytes
 * 
 * @example
 * ```typescript
 * const publicKey = Buffer.from('your_32_byte_public_key...', 'hex');
 * const dataHash = Buffer.from('sha256_of_your_data...', 'hex');
 * 
 * const ownership = createOwnershipCommitment(publicKey, dataHash);
 * console.log('Owner:', ownership.publicKey.toString('hex'));
 * console.log('Data:', ownership.dataHash.toString('hex'));
 * console.log('Commitment:', ownership.commitmentHash.toString('hex'));
 * ```
 */
export declare function createOwnershipCommitment(publicKey: Buffer, dataHash: Buffer): OwnershipCommitment

/**
 * Create anchored ownership commitment.
 * 
 * Combines an ownership commitment with a blockchain commitment to create
 * an immutable timestamp proving when the ownership was established.
 * This prevents backdating attacks and provides audit trails.
 * 
 * **Cryptographic Construction:**
 * `anchored_hash = SHA256(ownership_commitment_hash || block_hash)`
 * 
 * @param ownershipCommitment - The ownership commitment to anchor
 * @param blockCommitment - Blockchain block providing timestamp
 * @returns AnchoredOwnershipCommitment with timestamp proof
 * 
 * @example
 * ```typescript
 * const ownership = createOwnershipCommitment(publicKey, dataHash);
 * const blockCommitment = { blockHeight: 12345, blockHash: Buffer.from('...') };
 * 
 * const anchored = createAnchoredOwnershipCommitment(ownership, blockCommitment);
 * console.log('Anchored at block:', anchored.blockCommitment.blockHeight);
 * console.log('Anchored hash:', anchored.anchoredHash.toString('hex'));
 * ```
 */
export declare function createAnchoredOwnershipCommitment(ownershipCommitment: OwnershipCommitment, blockCommitment: BlockCommitment): AnchoredOwnershipCommitment

/**
 * Verify proof window.
 * 
 * Performs comprehensive cryptographic verification of a proof window,
 * ensuring it meets all network consensus requirements for Proof of
 * Storage Continuity.
 * 
 * **Verification Steps:**
 * 1. Validates proof window has exactly 8 commitments
 * 2. Verifies commitment chain integrity (sequential linking)
 * 3. Checks all chunk selections follow consensus algorithm
 * 4. Validates all Merkle proofs against merkle root
 * 5. Ensures all chunks are within valid range
 * 6. Confirms proper commitment hash calculations
 * 
 * **Network Requirements:**
 * - Exactly 8 sequential commitments
 * - Valid chunk selections per consensus algorithm
 * - Cryptographically valid Merkle proofs
 * - Proper commitment chain linking
 * 
 * @param proofWindow - The proof window to verify
 * @param anchoredCommitment - Initial anchored commitment (32 bytes)
 * @param merkleRoot - Merkle root for chunk verification (32 bytes)
 * @param totalChunks - Total chunks in the data file
 * @returns true if proof is valid and consensus-compliant, false otherwise
 * 
 * @example
 * ```typescript
 * // Generate proof window
 * const proofWindow = hashchain.getProofWindow();
 * const anchoredCommitment = hashchain.getAnchoredCommitment();
 * const merkleRoot = Buffer.from('merkle_root_32_bytes...', 'hex');
 * const totalChunks = hashchain.getTotalChunks();
 * 
 * // Verify proof
 * const isValid = verifyProof(
 *   proofWindow,
 *   anchoredCommitment,
 *   merkleRoot,
 *   totalChunks
 * );
 * 
 * if (isValid) {
 *   console.log('✅ Proof valid - storage continuity verified');
 *   // Submit to network
 * } else {
 *   console.log('❌ Proof invalid - do not submit');
 * }
 * ```
 */
export declare function verifyProof(proofWindow: ProofWindow, anchoredCommitment: Buffer, merkleRoot: Buffer, totalChunks: number): boolean

/**
 * Main HashChain implementation for Proof of Storage Continuity.
 * 
 * This class implements the complete HashChain Proof of Storage Continuity system
 * for the DIG Network. It provides deterministic, consensus-compliant storage
 * verification through continuous blockchain-anchored commitments.
 * 
 * **Core Functionality:**
 * - **Data Streaming**: Process data into 4KB chunks with content-addressable naming
 * - **Block Addition**: Add blockchain blocks every 16 seconds with deterministic chunk selection
 * - **Proof Generation**: Create network-compliant proof windows for validators
 * - **Chain Verification**: Validate entire chain against consensus requirements
 * 
 * **File Management:**
 * - `.hashchain` file: Contains metadata, merkle tree, and commitment chain
 * - `.data` file: Contains actual chunk data in 4KB blocks
 * - Files named using SHA256 hash of data content for content-addressable storage
 * 
 * **Network Consensus:**
 * - All operations follow DIG Network consensus specification
 * - Chunk selection uses deterministic algorithm V1
 * - Proof windows contain exactly 8 blocks (2-minute window at 16s intervals)
 * - All commitments cryptographically linked and verifiable
 * 
 * **Performance Characteristics:**
 * - Minimal memory footprint: ~1KB per instance
 * - File-based operations: Chain stored on disk, not in memory
 * - Efficient block addition: O(1) append operations
 * - Scalable: Supports hundreds of concurrent instances
 * 
 * **Lifecycle States:**
 * 1. **Uninitialized**: New instance, no data streamed
 * 2. **Initialized**: Data streamed, files created, ready for blocks
 * 3. **Building**: Blocks added, but < 8 blocks (proof window not ready)
 * 4. **Active**: 8+ blocks added, proof window ready for network submission
 * 
 * @example
 * ```typescript
 * // 1. Create new HashChain instance
 * const publicKey = Buffer.from('your_32_byte_public_key...', 'hex');
 * const initialBlockHeight = 12345;
 * const initialBlockHash = Buffer.from('initial_block_hash_32_bytes...', 'hex');
 * 
 * const hashchain = new HashChain(publicKey, initialBlockHeight, initialBlockHash);
 * 
 * // 2. Stream data to create files
 * const data = Buffer.from('your_data_here...');
 * const outputDir = './hashchain_storage';
 * 
 * hashchain.streamData(data, outputDir);
 * console.log('✅ Data streamed, files created');
 * 
 * // Files created with SHA256-based names:
 * // ./hashchain_storage/[sha256_hash].data
 * // ./hashchain_storage/[sha256_hash].hashchain
 * 
 * // 3. Add blockchain blocks every 16 seconds
 * const blocks = [
 *   Buffer.from('block_1_hash_32_bytes...', 'hex'),
 *   Buffer.from('block_2_hash_32_bytes...', 'hex'),
 *   // ... 6 more blocks for proof window
 * ];
 * 
 * for (const blockHash of blocks) {
 *   const commitment = hashchain.addBlock(blockHash);
 *   console.log(`Block added: ${commitment.selectedChunks.join(', ')}`);
 * }
 * 
 * // 4. Generate proof window (after 8+ blocks)
 * if (hashchain.getChainLength() >= 8) {
 *   const proofWindow = hashchain.getProofWindow();
 *   
 *   // Verify proof before network submission
 *   const isValid = verifyProof(
 *     proofWindow,
 *     hashchain.getAnchoredCommitment(),
 *     merkleRoot,
 *     hashchain.getTotalChunks()
 *   );
 *   
 *   if (isValid) {
 *     console.log('🎉 Ready for network proof submission!');
 *     // Submit proofWindow to DIG Network validators
 *   }
 * }
 * 
 * // 5. Monitor chain status
 * const info = hashchain.getChainInfo();
 * console.log(`Status: ${info.status}`);
 * console.log(`Storage: ${info.totalStorageMb.toFixed(2)} MB`);
 * console.log(`Proof Ready: ${info.proofWindowReady ? 'YES' : 'NO'}`);
 * ```
 * 
 * @example
 * ```typescript
 * // Load existing HashChain from file
 * const hashchain = HashChain.loadFromFile('./storage/abc123def456.hashchain');
 * 
 * console.log('Loaded chain:', {
 *   totalChunks: hashchain.getTotalChunks(),
 *   chainLength: hashchain.getChainLength(),
 *   currentCommitment: hashchain.getCurrentCommitment()?.toString('hex').slice(0, 8) + '...'
 * });
 * 
 * // Continue adding blocks
 * const newBlockHash = Buffer.from('new_block_hash...', 'hex');
 * const commitment = hashchain.addBlock(newBlockHash);
 * 
 * console.log('Block added:', {
 *   selectedChunks: commitment.selectedChunks,
 *   chunkHashes: commitment.chunkHashes.map(h => h.toString('hex').slice(0, 8) + '...')
 * });
 * ```
 */
export declare class HashChain {
  /**
   * Create new HashChain instance.
   * 
   * Initializes a new HashChain with blockchain parameters for proof of storage.
   * The instance starts in "uninitialized" state until data is streamed.
   * 
   * **Initial State:**
   * - No files created yet
   * - Ready to accept data via streamData()
   * - Anchored to specified blockchain block
   * 
   * @param publicKey - Owner's public key (must be exactly 32 bytes)
   * @param blockHeight - Initial blockchain block height for anchoring
   * @param blockHash - Initial blockchain block hash (must be exactly 32 bytes)
   * 
   * @throws {Error} If publicKey is not exactly 32 bytes
   * @throws {Error} If blockHash is not exactly 32 bytes
   * @throws {Error} If blockHeight is negative
   * 
   * @example
   * ```typescript
   * const publicKey = Buffer.from('your_32_byte_public_key...', 'hex');
   * const blockHeight = 12345;
   * const blockHash = Buffer.from('block_hash_32_bytes...', 'hex');
   * 
   * const hashchain = new HashChain(publicKey, blockHeight, blockHash);
   * console.log('HashChain initialized, ready for data streaming');
   * ```
   */
  constructor(publicKey: Buffer, blockHeight: number, blockHash: Buffer)

  /**
   * Load existing HashChain from .hashchain file.
   * 
   * Reconstructs a HashChain instance from previously saved files. Validates
   * file format compliance and loads minimal state for efficient operation.
   * 
   * **File Requirements:**
   * - Valid .hashchain file with proper header
   * - Corresponding .data file must exist
   * - Files must pass network consensus validation
   * 
   * **Loading Process:**
   * 1. Reads and validates file header
   * 2. Verifies data file existence and integrity
   * 3. Loads current chain state (no full chain in memory)
   * 4. Reconstructs instance ready for continued operation
   * 
   * @param hashchainFilePath - Path to existing .hashchain file
   * @returns HashChain instance loaded from file
   * 
   * @throws {Error} If hashchain file doesn't exist
   * @throws {Error} If corresponding data file doesn't exist
   * @throws {Error} If file format validation fails
   * @throws {Error} If file doesn't meet network consensus requirements
   * 
   * @example
   * ```typescript
   * // Load from existing file
   * const hashchain = HashChain.loadFromFile('./storage/abc123def456.hashchain');
   * 
   * console.log('Loaded HashChain:', {
   *   status: hashchain.getChainInfo().status,
   *   totalChunks: hashchain.getTotalChunks(),
   *   chainLength: hashchain.getChainLength(),
   *   filePaths: hashchain.getFilePaths()
   * });
   * 
   * // Continue adding blocks
   * const newBlock = Buffer.from('new_block_hash...', 'hex');
   * hashchain.addBlock(newBlock);
   * ```
   */
  static loadFromFile(hashchainFilePath: string): HashChain

  /**
   * Stream data to files with SHA256-based naming.
   * 
   * Processes input data into 4KB chunks, builds Merkle tree, and creates
   * both .data and .hashchain files with content-addressable names based
   * on SHA256 hash of the data.
   * 
   * **Processing Steps:**
   * 1. Splits data into 4KB chunks (last chunk padded if necessary)
   * 2. Calculates SHA256 hash of each chunk for Merkle tree
   * 3. Builds complete Merkle tree from chunk hashes
   * 4. Creates ownership and anchored commitments
   * 5. Writes data file with proper chunk alignment
   * 6. Writes hashchain file with header, merkle tree, and initial state
   * 7. Files named using SHA256 hash of original data
   * 
   * **File Outputs:**
   * - `{outputDir}/{sha256}.data` - Raw chunk data (4KB aligned)
   * - `{outputDir}/{sha256}.hashchain` - Metadata and commitment chain
   * 
   * **Network Compliance:**
   * - Enforces minimum 1 chunk, maximum 1,048,576 chunks (4TB)
   * - Uses exactly 4KB chunk size (consensus requirement)
   * - Creates network-compliant file format
   * 
   * @param data - Input data to process into chunks
   * @param outputDir - Directory for output files (created if doesn't exist)
   * 
   * @throws {Error} If HashChain already has data (call only once per instance)
   * @throws {Error} If data results in too many chunks (>1,048,576)
   * @throws {Error} If data results in too few chunks (<1)
   * @throws {Error} If output directory cannot be created
   * @throws {Error} If file write operations fail
   * 
   * @example
   * ```typescript
   * const hashchain = new HashChain(publicKey, blockHeight, blockHash);
   * const data = Buffer.from('your_data_content_here...');
   * const outputDir = './hashchain_storage';
   * 
   * hashchain.streamData(data, outputDir);
   * 
   * // Files created:
   * // ./hashchain_storage/abc123def456...789.data (contains chunks)
   * // ./hashchain_storage/abc123def456...789.hashchain (contains metadata)
   * 
   * const info = hashchain.getChainInfo();
   * console.log(`✅ Data streamed: ${info.totalChunks} chunks, ${info.totalStorageMb.toFixed(2)} MB`);
   * console.log(`Files: ${info.dataFilePath}, ${info.hashchainFilePath}`);
   * ```
   */
  streamData(data: Buffer, outputDir: string): void

  /**
   * Add new block to the hash chain.
   * 
   * Creates a new physical access commitment by selecting 4 chunks based on
   * the block hash and appending the commitment to the chain. This proves
   * continuous access to the data at the time of the specified block.
   * 
   * **Process:**
   * 1. Uses block hash as entropy for deterministic chunk selection
   * 2. Reads selected chunks from data file and computes their hashes
   * 3. Creates commitment linking to previous commitment
   * 4. Appends commitment to chain (file-based, not memory)
   * 5. Updates current commitment hash and chain length
   * 
   * **Consensus Requirements:**
   * - Block hash must be exactly 32 bytes
   * - Chunk selection follows consensus algorithm V1
   * - Exactly 4 unique chunks selected per block
   * - Commitment properly links to previous commitment
   * 
   * **Performance:**
   * - O(1) operation: reads 4 chunks + file append
   * - ~100ms typical execution time
   * - Minimal memory usage (~1KB temporary)
   * 
   * @param blockHash - Blockchain block hash providing entropy (32 bytes)
   * @returns PhysicalAccessCommitment proving storage at this block
   * 
   * @throws {Error} If blockHash is not exactly 32 bytes
   * @throws {Error} If no data has been streamed yet
   * @throws {Error} If chunk selection fails (unable to find 4 unique chunks)
   * @throws {Error} If data file read operations fail
   * 
   * @example
   * ```typescript
   * // Add blocks every 16 seconds (Chia block time)
   * const blockHashes = [
   *   Buffer.from('block_1_hash_32_bytes...', 'hex'),
   *   Buffer.from('block_2_hash_32_bytes...', 'hex'),
   *   Buffer.from('block_3_hash_32_bytes...', 'hex')
   * ];
   * 
   * for (const blockHash of blockHashes) {
   *   const commitment = hashchain.addBlock(blockHash);
   *   
   *   console.log(`Block ${hashchain.getChainLength()}:`, {
   *     selectedChunks: commitment.selectedChunks, // [123, 456, 789, 1011]
   *     chunkHashes: commitment.chunkHashes.map(h => h.toString('hex').slice(0, 8) + '...'),
   *     commitmentHash: commitment.commitmentHash.toString('hex').slice(0, 8) + '...'
   *   });
   * }
   * 
   * // Check if ready for proof generation
   * if (hashchain.getChainLength() >= 8) {
   *   console.log('🎉 Ready for proof window generation!');
   * } else {
   *   console.log(`⏳ Need ${8 - hashchain.getChainLength()} more blocks`);
   * }
   * ```
   */
  addBlock(blockHash: Buffer): PhysicalAccessCommitment

  /**
   * Verify entire hash chain.
   * 
   * Performs comprehensive validation of the entire HashChain against
   * network consensus requirements. Currently implements basic validation;
   * full implementation would verify all commitments and consensus compliance.
   * 
   * **Future Validation (planned):**
   * - File format compliance
   * - All commitment hashes properly calculated
   * - Chunk selections follow consensus algorithm
   * - Sequential commitment linking
   * - Merkle tree integrity
   * - Data file consistency
   * 
   * @returns true if chain is valid, false otherwise
   * 
   * @example
   * ```typescript
   * const isValid = hashchain.verifyChain();
   * 
   * if (isValid) {
   *   console.log('✅ Chain verification passed');
   * } else {
   *   console.log('❌ Chain verification failed');
   * }
   * ```
   */
  verifyChain(): boolean

  /**
   * Read chunk from data file.
   * 
   * Reads a specific 4KB chunk from the data file by index. Handles
   * file I/O and proper chunk alignment. Used internally for commitment
   * generation and externally for data access.
   * 
   * **Chunk Format:**
   * - Each chunk is exactly 4KB (4096 bytes)
   * - Last chunk may have padding bytes (zeros)
   * - Chunks numbered from 0 to totalChunks-1
   * 
   * @param chunkIdx - Index of chunk to read (0-based)
   * @returns Buffer containing chunk data (4096 bytes)
   * 
   * @throws {Error} If no data file is available
   * @throws {Error} If chunk index is out of range
   * @throws {Error} If file read operation fails
   * 
   * @example
   * ```typescript
   * // Read specific chunks
   * const chunk0 = hashchain.readChunk(0); // First chunk
   * const chunk5 = hashchain.readChunk(5); // Sixth chunk
   * const lastChunk = hashchain.readChunk(hashchain.getTotalChunks() - 1);
   * 
   * console.log('Chunk sizes:', {
   *   chunk0: chunk0.length, // 4096
   *   chunk5: chunk5.length, // 4096
   *   lastChunk: lastChunk.length // 4096 (may include padding)
   * });
   * 
   * // Verify chunk hashes
   * import { createHash } from 'crypto';
   * const chunk0Hash = createHash('sha256').update(chunk0).digest();
   * console.log('Chunk 0 hash:', chunk0Hash.toString('hex'));
   * ```
   */
  readChunk(chunkIdx: number): Buffer

  /**
   * Get current chain length.
   * 
   * Returns the number of blocks that have been added to the chain.
   * This represents the number of blockchain blocks for which storage
   * continuity has been proven.
   * 
   * @returns Number of blocks in the chain
   * 
   * @example
   * ```typescript
   * console.log(`Chain length: ${hashchain.getChainLength()} blocks`);
   * 
   * if (hashchain.getChainLength() >= 8) {
   *   console.log('✅ Proof window ready (8+ blocks)');
   * } else {
   *   const needed = 8 - hashchain.getChainLength();
   *   console.log(`⏳ Need ${needed} more blocks for proof window`);
   * }
   * ```
   */
  getChainLength(): number

  /**
   * Get total chunks.
   * 
   * Returns the total number of 4KB chunks in the data file.
   * This determines the range for chunk selection during commitments.
   * 
   * @returns Total number of chunks in the data
   * 
   * @example
   * ```typescript
   * const totalChunks = hashchain.getTotalChunks();
   * const totalSizeMB = (totalChunks * 4096) / (1024 * 1024);
   * 
   * console.log(`Data contains ${totalChunks} chunks`);
   * console.log(`Total size: ${totalSizeMB.toFixed(2)} MB`);
   * ```
   */
  getTotalChunks(): number

  /**
   * Get current commitment hash.
   * 
   * Returns the hash of the most recent commitment in the chain.
   * This represents the current state of the storage proof chain.
   * 
   * @returns Current commitment hash, or null if no commitments yet
   * 
   * @example
   * ```typescript
   * const current = hashchain.getCurrentCommitment();
   * 
   * if (current) {
   *   console.log('Current commitment:', current.toString('hex').slice(0, 16) + '...');
   * } else {
   *   console.log('No commitments yet - chain empty');
   * }
   * ```
   */
  getCurrentCommitment(): Buffer | null

  /**
   * Get anchored commitment hash.
   * 
   * Returns the initial anchored commitment that roots the entire chain.
   * This links the ownership and initial blockchain state immutably.
   * 
   * @returns Anchored commitment hash, or null if not initialized
   * 
   * @example
   * ```typescript
   * const anchored = hashchain.getAnchoredCommitment();
   * 
   * if (anchored) {
   *   console.log('Anchored commitment:', anchored.toString('hex').slice(0, 16) + '...');
   * } else {
   *   console.log('Not initialized - no anchored commitment');
   * }
   * ```
   */
  getAnchoredCommitment(): Buffer | null

  /**
   * Get file paths.
   * 
   * Returns the paths to both the .hashchain and .data files.
   * Useful for file management and debugging.
   * 
   * @returns Array containing [hashchainPath, dataPath], or null if not initialized
   * 
   * @example
   * ```typescript
   * const paths = hashchain.getFilePaths();
   * 
   * if (paths) {
   *   const [hashchainPath, dataPath] = paths;
   *   console.log('Files:', {
   *     hashchain: hashchainPath,
   *     data: dataPath
   *   });
   * } else {
   *   console.log('No files created yet');
   * }
   * ```
   */
  getFilePaths(): Array<string> | null

  /**
   * Get proof window for last 8 blocks (CONSENSUS CRITICAL).
   * 
   * Generates a proof window containing the last 8 block commitments plus
   * all necessary Merkle proofs for network verification. This is the
   * standard proof format for DIG Network submission.
   * 
   * **Proof Window Requirements:**
   * - Exactly 8 sequential block commitments
   * - 32 Merkle proofs total (8 blocks × 4 chunks each)
   * - Cryptographically linked commitment chain
   * - Verifiable against anchored commitment
   * 
   * **Network Submission:**
   * The returned proof window can be submitted to DIG Network validators
   * to prove continuous storage over the last 2-minute period (8 blocks
   * at 16-second intervals).
   * 
   * @returns ProofWindow containing last 8 commitments and Merkle proofs
   * 
   * @throws {Error} If chain length is less than 8 blocks
   * 
   * @example
   * ```typescript
   * // Generate proof window for network submission
   * if (hashchain.getChainLength() >= 8) {
   *   const proofWindow = hashchain.getProofWindow();
   *   
   *   console.log('Proof window generated:', {
   *     commitments: proofWindow.commitments.length, // 8
   *     merkleProofs: proofWindow.merkleProofs.length, // 32
   *     timespan: {
   *       start: proofWindow.startCommitment.toString('hex').slice(0, 8) + '...',
   *       end: proofWindow.endCommitment.toString('hex').slice(0, 8) + '...'
   *     }
   *   });
   *   
   *   // Verify proof before submission
   *   const isValid = verifyProof(
   *     proofWindow,
   *     hashchain.getAnchoredCommitment(),
   *     merkleRoot, // Would get from chain info
   *     hashchain.getTotalChunks()
   *   );
   *   
   *   if (isValid) {
   *     console.log('🎉 Proof valid - submitting to network');
   *     // Submit proofWindow to DIG Network validators
   *   } else {
   *     console.log('❌ Proof invalid - investigation required');
   *   }
   * } else {
   *   console.log(`⏳ Need ${8 - hashchain.getChainLength()} more blocks`);
   * }
   * ```
   */
  getProofWindow(): ProofWindow

  /**
   * Get file path for async operations (returns owned data).
   * 
   * Returns the path to the data file for use in async operations.
   * This method returns owned data (String) rather than borrowed data,
   * making it safe for async contexts and thread boundaries.
   * 
   * **Async Usage:**
   * Used by async functions that need to access the data file path
   * without borrowing from the HashChain instance.
   * 
   * @returns Data file path as owned string, or null if not initialized
   * 
   * @example
   * ```typescript
   * // Get path for async operations
   * const dataPath = hashchain.getDataFilePath();
   * 
   * if (dataPath) {
   *   console.log('Data file path:', dataPath);
   *   
   *   // Use in async contexts
   *   // readChunkAsync(dataPath, chunkIdx, totalChunks)
   * } else {
   *   console.log('No data file available');
   * }
   * ```
   */
  getDataFilePath(): string | null

  /**
   * Get comprehensive information about the HashChain state.
   * 
   * Returns detailed status information for monitoring, debugging,
   * user interfaces, and operational management. Includes file paths,
   * storage metrics, commitment tracking, and proof readiness.
   * 
   * **Information Categories:**
   * - **Status**: Current lifecycle state and readiness
   * - **Storage**: File sizes, chunk counts, storage requirements
   * - **Files**: Paths and file system information
   * - **Commitments**: Anchored and current commitment hashes
   * - **Proof**: Readiness for network proof generation
   * - **Network**: Consensus algorithm version and parameters
   * 
   * **Use Cases:**
   * - Status monitoring and alerting
   * - User interface display
   * - Performance tracking
   * - Storage management
   * - Network compliance verification
   * 
   * @returns HashChainInfo with comprehensive state information
   * 
   * @example
   * ```typescript
   * const info = hashchain.getChainInfo();
   * 
   * // Basic status check
   * console.log(`Status: ${info.status.toUpperCase()}`);
   * console.log(`Proof Ready: ${info.proofWindowReady ? '✅ YES' : '❌ NO'}`);
   * 
   * // Storage information
   * console.log(`Storage: ${info.totalChunks} chunks × ${info.chunkSizeBytes} bytes = ${info.totalStorageMb.toFixed(2)} MB`);
   * 
   * // File information
   * if (info.hashchainFilePath && info.dataFilePath) {
   *   console.log('Files:', {
   *     hashchain: {
   *       path: info.hashchainFilePath,
   *       size: `${(info.hashchainFileSizeBytes! / 1024).toFixed(1)} KB`
   *     },
   *     data: {
   *       path: info.dataFilePath,
   *       size: `${(info.dataFileSizeBytes! / 1024 / 1024).toFixed(2)} MB`
   *     }
   *   });
   * }
   * 
   * // Commitment tracking
   * if (info.anchoredCommitment && info.currentCommitment) {
   *   console.log('Commitments:', {
   *     anchored: info.anchoredCommitment.slice(0, 8) + '...',
   *     current: info.currentCommitment.slice(0, 8) + '...',
   *     blocks: info.chainLength
   *   });
   * }
   * 
   * // Proof readiness
   * if (info.proofWindowReady) {
   *   console.log('🎉 Ready for proof generation!');
   * } else if (info.blocksUntilProofReady) {
   *   console.log(`⏳ Need ${info.blocksUntilProofReady} more blocks`);
   * }
   * 
   * // Network compliance
   * console.log(`Algorithm: v${info.consensusAlgorithmVersion}`);
   * console.log(`Initial Block: ${info.initialBlockHeight}`);
   * ```
   */
  getChainInfo(): HashChainInfo
}
